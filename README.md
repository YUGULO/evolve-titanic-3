# Grupò 3: Ángel R, Andrés F & Jesús

# Vale chicos he echo copia pega de la tarea, estaria bien que 
# nos pongamos de acuerdo que es lo que vamos hacer cada uno.


# TITANIC

## Acerca de este proyecto

El objetivo de este proyecto es aprender a usar git con ejemplo de Titanic.


1. Título del Proyecto

Nombre claro y conciso: Por ejemplo, "Análisis de Supervivientes del Titanic con Streamlit"

Subtítulo (opcional): Una breve descripción del objetivo principal del proyecto.

2. Introducción

Breve resumen: Explica qué es el Titanic y por qué es un conjunto de datos popular para análisis.

Objetivo del proyecto: ¿Qué preguntas se buscan responder con este análisis? (e.g., ¿Qué factores influyeron en la supervivencia?)

Alcance del proyecto: ¿Qué aspectos del dataset se exploran? ¿Qué técnicas se utilizan?

3. Datos Utilizados

Fuente de los datos: De dónde se obtuvieron los datos (Kaggle, etc.)

Descripción general del dataset: Número de filas, columnas, variables principales.

Limpieza y preprocesamiento: Breve descripción de las tareas realizadas para preparar los datos para el análisis (manejo de valores faltantes, transformación de variables, etc.).

4. Funcionalidades de la Aplicación

Visualizaciones: ¿Qué tipos de visualizaciones se incluyen? (histogramas, gráficos de barras, diagramas de dispersión, etc.)

Interactividad: ¿Cómo puede el usuario interactuar con la aplicación? (filtros, selectores, etc.)

Análisis clave: ¿Cuáles son los hallazgos más importantes del análisis?


# Esta es la aportacion de Andrés Felipe Bustillo


README.md: Análisis de Supervivientes del Titanic con Streamlit

 # Introducción
Objetivo: Predecir la supervivencia de pasajeros en el Titanic utilizando técnicas de aprendizaje automático.
Datos: Utilizaremos el dataset del Titanic disponible en Kaggle para entrenar y evaluar nuestros modelos.
Herramientas: Streamlit para crear una aplicación web interactiva, Python para el análisis de datos y aprendizaje automático.
# Estructura del proyecto
notebooks: Contiene los notebooks de Jupyter donde se realiza el análisis de datos, la limpieza, la exploración y el entrenamiento de los modelos.
src: Contiene el código fuente de la aplicación Streamlit, incluyendo las visualizaciones y la lógica de la aplicación.
data: Contiene los datos utilizados en el proyecto, tanto los datos originales como los procesados.
models: Contiene los modelos entrenados que se utilizarán para hacer predicciones.

